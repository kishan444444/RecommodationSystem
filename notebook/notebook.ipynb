{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>view_time_seconds</th>\n",
       "      <th>like_time_seconds</th>\n",
       "      <th>inspiration_time_seconds</th>\n",
       "      <th>rating_percent</th>\n",
       "      <th>rated_posts_time_seconds</th>\n",
       "      <th>slug</th>\n",
       "      <th>title</th>\n",
       "      <th>identifier</th>\n",
       "      <th>username</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>mood_score</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>631.0</td>\n",
       "      <td>114</td>\n",
       "      <td>26455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7936.7</td>\n",
       "      <td>0.306881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18937.1</td>\n",
       "      <td>0.732234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>517.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>63771.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12754.4</td>\n",
       "      <td>0.493168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>626.0</td>\n",
       "      <td>114</td>\n",
       "      <td>26478.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we-are-made-of-stars</td>\n",
       "      <td>WE ARE MADE OF STARS</td>\n",
       "      <td>ATg3vKN</td>\n",
       "      <td>johntest</td>\n",
       "      <td>7943.6</td>\n",
       "      <td>0.307148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dc0f546db4616da5595779eadd4afb5efab21837</td>\n",
       "      <td>Do not fear I am with you</td>\n",
       "      <td>isW62Tj</td>\n",
       "      <td>vishnumurthy</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671287dfb297579e1a6647017e36e66b077fc70c</td>\n",
       "      <td>Jai Shri Ram   Manojavam Marutatulya</td>\n",
       "      <td>ckTMNyQ</td>\n",
       "      <td>ypk4my5sq9_01l1c4i8f</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3a49f9ed74e466e135ccd73d473a77d133f37a38</td>\n",
       "      <td>first meet of shatrughan with love kush</td>\n",
       "      <td>Fom2XOH</td>\n",
       "      <td>kjy8frhg6t_08f2l3c8i</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8143de1267f0cbcd19360c7fec83d220641e4cb9</td>\n",
       "      <td>Ramayan part 20</td>\n",
       "      <td>wS9HaNG</td>\n",
       "      <td>2r6m2grxsy_09l6c6f6i</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98b2f413277624e180a77089206cd4d038ec7e2b</td>\n",
       "      <td>I believe you can do a miracale in my life</td>\n",
       "      <td>Pr6_oSt</td>\n",
       "      <td>nxmxhwh2pw_01i1l6f0c</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3252 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  post_id  user_id  ...  normalized_score  mood_score      mood\n",
       "0      18    631.0      114  ...          0.306881         0.0  Negative\n",
       "1      18     64.0       18  ...          0.732234         0.0  Negative\n",
       "2      18    469.0        1  ...          0.000000         0.0  Negative\n",
       "3      18    517.0        1  ...          0.493168         0.0  Negative\n",
       "4      19    626.0      114  ...          0.307148         0.0  Negative\n",
       "...   ...      ...      ...  ...               ...         ...       ...\n",
       "3247  687      0.0        0  ...          0.000000         0.0  Negative\n",
       "3248  702      0.0        0  ...          0.000000         0.0  Negative\n",
       "3249  805      0.0        0  ...          0.000000         0.0  Negative\n",
       "3250  860      0.0        0  ...          0.000000         0.0  Negative\n",
       "3251  867      0.0        0  ...          0.000000         0.0  Negative\n",
       "\n",
       "[3252 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#header for API authorization\n",
    "headers = {\n",
    "    'Flic-Token': 'flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8'\n",
    "}\n",
    "\n",
    "\n",
    "# API Endpoints (Replace with your actual URLs)\n",
    "VIEWED_POSTS_API = \"https://api.socialverseapp.com/posts/view?page=1&page_size=1000&resonance_algorithm=resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "LIKED_POSTS_API = \"https://api.socialverseapp.com/posts/like?page=1&page_size=1000&resonance_algorithm=resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "INSPIRED_POSTS_API = \"https://api.socialverseapp.com/posts/inspire?page=1&page_size=1000&resonance_algorithm=resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "RATED_POSTS_API = \"https://api.socialverseapp.com/posts/rating?page=1&page_size=1000&resonance_algorithm=resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "All_POSTS_API= 'https://api.socialverseapp.com/posts/summary/get?page=1&page_size=1000'\n",
    "ALL_USER_API='https://api.socialverseapp.com/users/get_all?page=1&page_size=1000' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1️⃣ Data Retrieval (API Calls)\n",
    "def fetch_data(api_url):\n",
    "    \"\"\"Fetch data from API and return as DataFrame.\"\"\"\n",
    "    response = requests.get(api_url,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return pd.DataFrame(response.json())\n",
    "    else:\n",
    "        print(f\"Error fetching data from {api_url}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch data from all APIs\n",
    "# Fetch data from all APIs\n",
    "viewed_posts = fetch_data(VIEWED_POSTS_API)\n",
    "viewed_posts=pd.json_normalize(viewed_posts['posts'])\n",
    "liked_posts = fetch_data(LIKED_POSTS_API)\n",
    "liked_posts = pd.json_normalize(liked_posts['posts'])\n",
    "inspired_posts = fetch_data(INSPIRED_POSTS_API)\n",
    "inspired_posts= pd.json_normalize(inspired_posts['posts'])\n",
    "rated_posts = fetch_data(RATED_POSTS_API)\n",
    "rated_posts= pd.json_normalize(rated_posts['posts'])\n",
    "all_post=fetch_data(All_POSTS_API)\n",
    "all_post=pd.json_normalize(all_post['posts'])\n",
    "all_post=all_post[['id','slug','title','identifier']]\n",
    "all_user=fetch_data(ALL_USER_API)\n",
    "all_user=pd.json_normalize(all_user['users'])\n",
    "all_user=all_user[['id','username']]\n",
    "\n",
    "def time_to_seconds(time_str):\n",
    "    # Extract time part from 'YYYY-MM-DD HH:MM:SS' and split by ':'\n",
    "    time_part = time_str.split()[1]\n",
    "    h, m, s = map(int, time_part.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "viewed_posts['view_time_seconds'] = viewed_posts['viewed_at'].apply(time_to_seconds)\n",
    "liked_posts['like_time_seconds'] = liked_posts['liked_at'].apply(time_to_seconds)\n",
    "inspired_posts['inspiration_time_seconds'] = inspired_posts['inspired_at'].apply(time_to_seconds)\n",
    "rated_posts['rated_posts_time_seconds']=rated_posts['rated_at'].apply(time_to_seconds)\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "viewed_posts.drop_duplicates(subset=['user_id', 'post_id'], inplace=True)\n",
    "liked_posts.drop_duplicates(subset=['user_id', 'post_id'], inplace=True)\n",
    "inspired_posts.drop_duplicates(subset=['user_id', 'post_id'], inplace=True)\n",
    "rated_posts.drop_duplicates(subset=['user_id', 'post_id'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Normalize engagement scores\n",
    "scaler = MinMaxScaler()\n",
    "engagement_data = pd.merge(viewed_posts, liked_posts, on=['user_id', 'post_id','id'], how='outer')\n",
    "engagement_data = pd.merge(engagement_data, inspired_posts, on=['user_id', 'post_id','id'], how='outer')\n",
    "engagement_data = pd.merge(engagement_data, rated_posts, on=['user_id', 'post_id','id'], how='outer')\n",
    "video_megadata=pd.merge(all_post, all_user, on='id', how='outer', suffixes=('_left', '_right'))\n",
    "video_megadata = video_megadata.dropna()\n",
    "engagement_data=pd.merge(engagement_data,video_megadata, on='id',how='outer')\n",
    "engagement_data.fillna(0, inplace=True)\n",
    "\n",
    "engagement_data.drop(columns=['viewed_at', 'liked_at', 'inspired_at','rated_at'], inplace=True)\n",
    "\n",
    "engagement_data['user_id']=engagement_data['user_id'].astype(int)\n",
    "\n",
    "# Calculate a unified engagement score\n",
    "engagement_data['engagement_score'] = (\n",
    "    (engagement_data['view_time_seconds'] * (0.3)) +\n",
    "    (engagement_data['like_time_seconds'] * (0.3)) +\n",
    "    (engagement_data['inspiration_time_seconds'].notnull().astype(int) * (0.2)) +\n",
    "    (engagement_data['rated_posts_time_seconds'] * (0.2))\n",
    ")\n",
    "\n",
    "# Normalize engagement scores\n",
    "engagement_data['normalized_score'] = scaler.fit_transform(engagement_data[['engagement_score']])\n",
    "\n",
    "# Mood Calculation (custom logic)\n",
    "engagement_data['mood_score'] = (engagement_data['like_time_seconds'] / engagement_data['view_time_seconds']) * engagement_data['rating_percent']\n",
    "engagement_data['mood_score'].fillna(0, inplace=True)\n",
    "engagement_data['mood'] = engagement_data['mood_score'].apply(lambda x: 'Positive' if x > 50 else 'Negative')\n",
    "\n",
    "\n",
    "engagement_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  15179.0771\n",
      "RMSE: 16542.3982\n",
      "No predictions found for user_id 114, using default predictions.\n",
      "Top 10 recommended post IDs for user 'vishnumurthy' (user ID 114) and mood 'positive':\n",
      "[631.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import SVD, Dataset, Reader, accuracy  # Import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'engagement_data' is already loaded as a DataFrame\n",
    "df = engagement_data  # Your engagement dataset\n",
    "\n",
    "# Ensure 'title' is in string format for TF-IDF processing\n",
    "df['title'] = df['title'].astype(str)\n",
    "\n",
    "# Step 1: Content-based Filtering (TF-IDF)\n",
    "def compute_content_scores(df, mood=None):\n",
    "    \"\"\"Compute content-based scores using TF-IDF.\"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df['title'])\n",
    "    \n",
    "    if mood:\n",
    "        mood_based_post_idx = df[df['mood'].str.lower() == mood.lower()].index\n",
    "        if not mood_based_post_idx.empty:\n",
    "            content_scores = cosine_similarity(tfidf_matrix[mood_based_post_idx[0]], tfidf_matrix)\n",
    "        else:\n",
    "            content_scores = cosine_similarity(tfidf_matrix[0], tfidf_matrix)\n",
    "    else:\n",
    "        content_scores = cosine_similarity(tfidf_matrix[0], tfidf_matrix)\n",
    "    \n",
    "    return content_scores.ravel()  # Convert to 1D array\n",
    "\n",
    "# Step 2: Collaborative Filtering (SVD)\n",
    "def train_svd_model(df):\n",
    "    \"\"\"Train an SVD model for collaborative filtering and calculate MAE and RMSE.\"\"\"\n",
    "    reader = Reader(rating_scale=(df['engagement_score'].min(), df['engagement_score'].max()))\n",
    "    data = Dataset.load_from_df(df[['user_id', 'post_id', 'engagement_score']], reader)\n",
    "    \n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "    \n",
    "    model = SVD()\n",
    "    model.fit(trainset)\n",
    "    \n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    # Calculate MAE and RMSE\n",
    "    mae = accuracy.mae(predictions, verbose=True)\n",
    "    rmse = accuracy.rmse(predictions, verbose=True)\n",
    "    \n",
    "    return model, predictions, mae, rmse\n",
    "\n",
    "# Step 3: Hybrid Model\n",
    "def hybrid_recommendation(username, user_id, mood=None, alpha=0.6, beta=0.4):\n",
    "    \"\"\"\n",
    "    Hybrid recommendation system that combines content-based and collaborative filtering.\n",
    "    Returns:\n",
    "        list: List of recommended post IDs for the user.\n",
    "    \"\"\"\n",
    "    # Step 1: Content-based scores\n",
    "    content_scores = compute_content_scores(df, mood=mood)\n",
    "    df['content_score'] = content_scores  # Store the content scores in the DataFrame\n",
    "    \n",
    "    # Step 2: Collaborative Filtering\n",
    "    model, predictions, mae, rmse = train_svd_model(df)  # Get MAE and RMSE here\n",
    "    \n",
    "    # Extract collaborative scores for the given user\n",
    "    user_predictions = [pred for pred in predictions if pred.uid == str(user_id)]\n",
    "    \n",
    "    if not user_predictions:\n",
    "        print(f\"No predictions found for user_id {user_id}, using default predictions.\")\n",
    "        user_predictions = predictions  # Default to all predictions if user_id not found\n",
    "    \n",
    "    # Extract collaborative scores and align them with post IDs\n",
    "    collaborative_df = pd.DataFrame({\n",
    "        'post_id': [pred.iid for pred in user_predictions],\n",
    "        'collaborative_score': [pred.est for pred in user_predictions]\n",
    "    })\n",
    "    \n",
    "    # Merge collaborative scores with the main DataFrame\n",
    "    merged_df = pd.merge(df, collaborative_df, on='post_id', how='left')\n",
    "    \n",
    "    # Replace NaN collaborative scores with 0\n",
    "    merged_df['collaborative_score'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Step 3: Calculate the hybrid final score\n",
    "    merged_df['final_score'] = (alpha * merged_df['content_score']) + (beta * merged_df['collaborative_score'])\n",
    "    \n",
    "    # Step 4: Rank and recommend top 10 posts\n",
    "    recommended_posts = merged_df.sort_values(by='final_score', ascending=False).head(10)\n",
    "    \n",
    "    # Return the recommended post IDs\n",
    "    return recommended_posts['post_id'].tolist(), mae, rmse\n",
    "\n",
    "# Example usage:\n",
    "username = \"vishnumurthy\"  # User's name\n",
    "user_id = 114 # Example user ID\n",
    "mood = \"positive\"  # Example mood\n",
    "\n",
    "recommended_posts, mae, rmse = hybrid_recommendation(username, user_id, mood)\n",
    "\n",
    "# Output the top 10 recommended post IDs\n",
    "if recommended_posts:\n",
    "    print(f\"Top 10 recommended post IDs for user '{username}' (user ID {user_id}) and mood '{mood}':\")\n",
    "    print(recommended_posts)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
